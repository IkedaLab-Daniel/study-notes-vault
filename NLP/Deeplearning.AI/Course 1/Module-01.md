# Natural Langugage Processing With Classification  and Vector Spaces
- DeepLearning.AI

## Intro to the NLP Specialization & Course 1 Overview

The instructors—Andrew, Younes, and Lukasz—introduce the NLP Specialization and outline its evolution from rule-based systems to modern deep learning methods. Advances in computing and attention mechanisms now allow efficient training of complex NLP models used in applications like chatbots, question answering, and machine translation.

The specialization contains four courses:

* **Course 1:** Classification and vector spaces. You’ll build sentiment classifiers using logistic regression and Naive Bayes, and learn vector representations for text. You’ll also build a simple machine translation system and use locality-sensitive hashing for efficient search.
* **Course 2:** Probabilistic models for predicting the likelihood of the next word.
* **Course 3:** Sequence models.
* **Course 4:** Attention models powering state-of-the-art NLP systems like chatbots and summarizers.

Within **Course 1**, the weekly breakdown is:

* **Week 1:** Text representation as vectors and logistic regression for sentiment.
* **Week 2:** Naive Bayes for sentiment classification.
* **Week 3:** Vector space models for tasks like retrieval and ranking.
* **Week 4:** Simple machine translation + locality-sensitive hashing for faster nearest-neighbor search.

The course prepares you to build foundational NLP systems and understand the core concepts behind modern applications.
